{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import patsy\n",
    "from IPython.display import HTML\n",
    "import statsmodels\n",
    "\n",
    "pd.options.display.max_columns = 150\n",
    "_chars_per_line = 117\n",
    "\n",
    "# Many thanks to lucacerone and harshil for their contribution to StackOverflow.\n",
    "html_script = '''<script>code_show=true;function code_toggle(){if (code_show){\n",
    " $('div.input').hide();}else{$('div.input').show();}code_show = !code_show}\n",
    " $( document ).ready(code_toggle);</script><form action=\"javascript:code_toggle()\">\n",
    " <input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>'''\n",
    "\n",
    "def code_toggle(): return HTML(html_script.replace('true','false'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://thetomatos.com/wp-content/uploads/2016/02/house-clipart-vector-graphics-house-eps-clip-art-vector.jpg\" style=\" margin: 15px; height: 120px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1:  Regression and classification with housing data\n",
    "\n",
    "### Goals:\n",
    "\n",
    "There are three goals this project seeks to achive from a technical perspective:\n",
    "\n",
    "    1. To create a predictive model for the sale price of a property based on its \"fixed\" and \"known\" characteristics.\n",
    "    2. To create a predictive model for sale price of a property as a function of its \"alterable\" qualities.\n",
    "    3. To determine the features in the housing data that best predict \"abnormal\" sales.\n",
    "\n",
    "Furthermore, in service to the reader (and ourselves) we seek to:\n",
    "\n",
    "    I.   Present the data, methods and assumptions we are working with in a clear and explicit manner.\n",
    "    II.  Justify the decicions we make towards the development of our model, and its evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GlobalHelper:\n",
    "    \n",
    "    global immutable_replace\n",
    "    def immutable_replace(entry,dictionary = {}):\n",
    "        if entry in dictionary.keys():\n",
    "            return dictionary[entry]\n",
    "        else:\n",
    "            return entry \n",
    "        \n",
    "    global immutable_replace_with_unknowns\n",
    "    def immutable_replace_with_unknowns(ser, dictionary, unknown = 'CouldNotBeInferred'):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    global scale_dataframe\n",
    "    def scale_dataframe(df, method = 'StandardScaler'):\n",
    "        if method == 'StandardScaler':\n",
    "            scaler = StandardScaler()\n",
    "        elif method == 'MinMaxScaler':\n",
    "            scaler = MinMaxScaler()\n",
    "        scaler.fit(df)\n",
    "        return pd.DataFrame(columns=df.columns,data=scaler.transform(df))\n",
    "    \n",
    "    global plist\n",
    "    def plist(list_to_print = [], spacing = 14, col_num = 8):\n",
    "        '''Prints a list in a pretty way'''\n",
    "        list_items = [str(item).ljust(spacing) for item in list_to_print]\n",
    "        for i in range(0,len(list_to_print),col_num): \n",
    "            [print(list_items[j],end='') for j in range(i,i+col_num) if j < len(list_to_print)]\n",
    "            print()\n",
    "\n",
    "    global extended_type\n",
    "    def extended_type(x):\n",
    "        if x != x:\n",
    "            return \"<class 'missing'>\"\n",
    "        else:\n",
    "            return str(type(x))\n",
    "\n",
    "    global get_m_n\n",
    "    def get_m_n(N):\n",
    "        '''find m,n such that an m*n grid can hold N values in a pleasing way'''\n",
    "        for m in range(int(np.ceil(np.sqrt(N))),N+1):\n",
    "            for k in range(0,m):\n",
    "                A = m**2 + m*k\n",
    "                B = m/2 -1 + m**2 -k*m - m\n",
    "                if B < N and A >= N: \n",
    "                    return (m,m-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataFrameHelper(pd.DataFrame):\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    def set_checkpoint(self):\n",
    "        self.history.append('set_checkpoint')\n",
    "        self.checkpoint = self\n",
    "   \n",
    "    def reset(self):\n",
    "        try:\n",
    "            self.history.append('reset')\n",
    "            self = self.checkpoint\n",
    "        except:\n",
    "            self.history.append('reset failed')\n",
    "            print('reseting failed')\n",
    "            \n",
    "\n",
    "    def explore_types(self, columns = None):      \n",
    "        if columns == None: columns = self.columns\n",
    "        \n",
    "        di = {key:self[key].apply(extended_type).value_counts() for key in columns}\n",
    "        return pd.DataFrame(columns = columns, data = di)\n",
    "    \n",
    "    def pcolumns(self,columns = None, spacing = 14, col_num = 8):\n",
    "        '''Prints the column names in a pretty way. \n",
    "        The default is to print all columns, but a list may be passed.'''\n",
    "        if columns == None: columns = self.columns\n",
    "        plist(columns, spacing, col_num)\n",
    "    \n",
    "    def puniques(self,columns, spacing=7,col_num=16):\n",
    "        for col in columns:\n",
    "            print(col+':\\n{}'.format('_'*115))\n",
    "            plist(self[col].unique(), spacing=spacing,col_num=col_num)\n",
    "            print()\n",
    "    \n",
    "    def plot_value_occurences(self,normed = False, columns = None, \n",
    "                              fig_size = (15,15), xmarks = False,mn = None):\n",
    "        if columns == None: columns = self.columns.tolist()\n",
    "            \n",
    "        num_of_cols = len(columns)\n",
    "        print('Generating ',num_of_cols,' plots')\n",
    "        if mn == None:\n",
    "            m,n = get_m_n(num_of_cols)\n",
    "        else:\n",
    "            m,n = mn\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.figure(figsize=fig_size)\n",
    "        plt.suptitle('Histogram of unique values',fontsize=25)\n",
    "        \n",
    "        for i in range(num_of_cols):\n",
    "            col = columns[i]\n",
    "            plt.subplot(m,n,i+1)\n",
    "            plt.title(col)\n",
    "            self[col].value_counts(dropna = False).plot(kind='bar')\n",
    "            if xmarks == False: plt.xticks([])\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        plt.show()\n",
    "        return None\n",
    "    \n",
    "    def plot_poly_regplot(self,target,deg = 1, columns = None, \n",
    "                              fig_size = (15,15), xmarks = False,mn = None,\n",
    "                              low = False):\n",
    "        if columns == None: columns = self.describe().columns.tolist()\n",
    "            \n",
    "        num_of_cols = len(columns)\n",
    "        print('Generating ',num_of_cols,' plots')\n",
    "        if mn == None:\n",
    "            m,n = get_m_n(num_of_cols)\n",
    "        else:\n",
    "            m,n = mn\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.figure(figsize=fig_size)\n",
    "        plt.suptitle('Polynomial fit of unique values',fontsize=25)\n",
    "        \n",
    "        for i in range(num_of_cols):\n",
    "            try:\n",
    "                col = columns[i]\n",
    "                plt.subplot(m,n,i+1)\n",
    "                plt.title(col)\n",
    "                sns.regplot(self[col],self[target], order = deg, lowess= low)\n",
    "                if xmarks == False: plt.xticks([])\n",
    "            except:\n",
    "                print('Something went wrong while exploring {}'.format(columns[i]))\n",
    "                pass\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        plt.show()\n",
    "        return None\n",
    "    \n",
    "    def plot_types(self, columns = None, split = 4, figsize = (17,2)):\n",
    "        plt.clf()\n",
    "        self.explore_types(columns = columns).T.plot(kind='bar',figsize=figsize, stacked=True, legend=None)\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "        plt.suptitle('Occurence of types in attributes',fontsize=25)\n",
    "        plt.subplots_adjust(top=0.80)\n",
    "        plt.show()\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     60,
     93
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ProjectHelper(DataFrameHelper):\n",
    "    '''This Class is hard coded for this project. Its methods are useful for data cleaning.'''\n",
    "    \n",
    "    #definition of essentialy nessesary data cleaning\n",
    "    def impute_typos(self):\n",
    "        COPY = self.copy()\n",
    "        COPY.history.append('impute_typos')\n",
    "        COPY.loc[948,'BsmtExposure'] = 'No'\n",
    "        COPY.loc[332,'BsmtFinType2'] = 'Unf'\n",
    "        COPY.loc[1379,'Electrical'] = 'SBrkr'\n",
    "        return COPY\n",
    "    \n",
    "    def impute_correct_type_to_MSSubClass(self):\n",
    "        self.history.append('impute_correct_type_to_MSSubClass')\n",
    "        \n",
    "        MSSubClass_dict ={\n",
    "            20:'1-STORY 1946 & NEWER ALL STYLES',\n",
    "            30:'1-STORY 1945 & OLDER',\n",
    "            40:'1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "            45:'1-1/2 STORY - UNFINISHED ALL AGES',\n",
    "            50:'1-1/2 STORY FINISHED ALL AGES',\n",
    "            60:'2-STORY 1946 & NEWER',\n",
    "            70:'2-STORY 1945 & OLDER',\n",
    "            75:'2-1/2 STORY ALL AGES',\n",
    "            80:'SPLIT OR MULTI-LEVEL',\n",
    "            85:'SPLIT FOYER',\n",
    "            90:'DUPLEX - ALL STYLES AND AGES',\n",
    "            120:'1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n",
    "            150:'1-1/2 STORY PUD - ALL AGES',\n",
    "            160:'2-STORY PUD - 1946 & NEWER',\n",
    "            180:'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n",
    "            190:'2 FAMILY CONVERSION - ALL STYLES AND AGES'}\n",
    "        \n",
    "        self['MSSubClass'] = self['MSSubClass'].apply(lambda x: immutable_replace(x,MSSubClass_dict))\n",
    "\n",
    "    def impute_0_to_nan(self):\n",
    "        '''We impute 0 to nan for every occurence in some columns (because 0 is a suitable value of an area)'''\n",
    "        self.history.append('impute_0_to_nan')\n",
    "        \n",
    "        for col in ['LotFrontage','MasVnrArea']:\n",
    "            self[col].fillna(value = 0,inplace=True)\n",
    "    \n",
    "    def impute_None_to_nan(self):\n",
    "        '''We impute the string 'None' to nan (because no such feature is present)'''\n",
    "        \n",
    "        self.history.append('impute_None_to_nan')\n",
    "        for col in ['Alley','MasVnrType','BsmtFinType2','GarageType','PoolQC','Fence','MiscFeature']:\n",
    "            self[col].fillna(value = 'None',inplace=True)\n",
    "    \n",
    "    def impute_NotApplicable_to_nan(self):\n",
    "        '''We impute 'NotApplicable' to nan (because this is an atribute of a feature that is not present)'''\n",
    "        self.history.append('impute_NotApplicable_to_nan')\n",
    "        \n",
    "        for col in ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','FireplaceQu','GarageYrBlt',\n",
    "                    'GarageFinish','GarageQual','GarageCond']:\n",
    "            self[col].fillna(value = 'NotApplicable',inplace=True)\n",
    "        \n",
    "        \n",
    "  \n",
    "    # Perform the above imputation methods one after another.\n",
    "    def impute(self):\n",
    "        self.history.append('impute...')\n",
    "        self.impute_typos()\n",
    "        self.impute_correct_type()\n",
    "        self.impute_0_to_nan()\n",
    "        self.impute_None_to_nan()\n",
    "        self.impute_NotApplicable_to_nan()\n",
    "    \n",
    "    #definition of 'optional' data cleaning\n",
    "    def cast_quality_to_numbers(self,NA = 0):\n",
    "        self.history.append('cast_quality_to_numbers')\n",
    "        quality_to_number_dict = {\n",
    "           'Ex':5,\n",
    "           'Gd':4,\n",
    "           'TA':3,\n",
    "           'Fa':2,\n",
    "           'Po':1,\n",
    "           'NA':NA,\n",
    "           'NotApplicable': NA}\n",
    "        \n",
    "        for col in ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
    "                    'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']:\n",
    "            self[col] = self[col].apply(lambda x: immutable_replace(x,quality_to_number_dict))\n",
    "    \n",
    "    def cast_land_slope_to_numbers(self):\n",
    "        self.history.append('cast_land_slope_to_numbers')\n",
    "        LandSlope_dict = {\n",
    "           'Gtl':0, #Gentle slope\n",
    "           'Mod':1, #Moderate Slope\n",
    "           'Sev':2} #Severe Slope\n",
    "        self['LandSlope'] = self['LandSlope'].apply(lambda x: immutable_replace(x,LandSlope_dict))       \n",
    "    \n",
    "    #definition of methods for quality of life improvements.\n",
    "    def get_years(self,LIST = [2010]):\n",
    "        if not isinstance(LIST,list): LIST = [LIST]\n",
    "        mask = [True if x in LIST else False for x in self['YrSold']]\n",
    "        return self[mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelingReport:\n",
    "    def __init__(self,model,X,y,naive_score,cv_score,true_score):\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.y = y \n",
    "        self.naive_score = naive_score\n",
    "        self.cv_score = cv_score\n",
    "        self.true_score = true_score\n",
    "        self.stored_settings = None\n",
    "    \n",
    "    def to_df(self):\n",
    "        rec = pd.DataFrame(columns=['report', 'model','naive_score','true_score','cv_score'],\n",
    "                           data={'report':self,'model':self.model,'naive_score':self.naive_score,\n",
    "                                 'cv_score':self.cv_score,'true_score':self.true_score},index = ['rec:'])\n",
    "        \n",
    "        if self.stored_settings != None:\n",
    "            settings = pd.DataFrame(self.stored_settings,index=['rec:'])\n",
    "            rec = pd.concat([rec,settings],axis=1)\n",
    "        return rec\n",
    "    \n",
    "    def remember_config(self,di):\n",
    "        self.stored_settings = di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def implement_modeling(\n",
    "    df,\n",
    "    target = 'SalePrice',\n",
    "    ignore_colums = None,\n",
    "    consider_columns = None,\n",
    "    \n",
    "    model='lm',\n",
    "    model_alpha = 1,\n",
    "    \n",
    "    get_dummies = True, \n",
    "    dummy_columns = None,\n",
    "    do_drop_first = False,\n",
    "    \n",
    "\n",
    "    scale_technique = None):\n",
    "    \n",
    "    '''This function performs most actions that would normaly be associated to implementing \n",
    "    and assessing a regression model.\n",
    "    \n",
    "    it returns an object called model_report that contains \n",
    "    the key elements of the implementation and assesment as atributes.\n",
    "    \n",
    "    The model_report contains as atributes the model and feature matrix \n",
    "    so that further exploration can be done with ease'''\n",
    "    \n",
    "    try:\n",
    "        test = (df['YrSold'] == 2010).values\n",
    "        train = (df['YrSold'] != 2010).values\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    X = df.drop([target],axis=1)\n",
    "    y = df[target]\n",
    "    \n",
    "    # using specific colums or ignoring others\n",
    "    if consider_columns != None:\n",
    "        X = X[consider_columns]\n",
    "    if ignore_colums != None:\n",
    "        X = X.drop([col for col in ignore_colums if col in X.columns],axis = 1)\n",
    "    \n",
    "    # Select a model and initialize it with the appropiate hyperparameters\n",
    "    if model == 'lm':\n",
    "        model = LinearRegression()\n",
    "    elif model == 'ridge':\n",
    "        model = Ridge(alpha = model_alpha)\n",
    "    elif model == 'lasso':\n",
    "        model = Lasso(alpha = model_alpha)\n",
    "\n",
    "    # Get dummie variables\n",
    "    # This will dummify columns if you specify them, or dummify all non numeric columns if you do not\n",
    "    \n",
    "    if get_dummies == True or dummy_columns != None:\n",
    "        if dummy_columns == None: dummy_columns = [col for col in X.columns if col not in X.describe().columns]\n",
    "        X = pd.get_dummies(data = X,columns = dummy_columns, drop_first=do_drop_first)\n",
    "        X.columns = [col.replace(' ','_') for col in X.columns]\n",
    "    else:\n",
    "        if dummy_columns == None: dummy_columns = [col for col in X.columns if col not in X.describe().columns]\n",
    "        X = X.drop(dummy_columns,axis=1)\n",
    "\n",
    "    # Perform scaling\n",
    "    \n",
    "    if scale_technique != None:\n",
    "        X = scaler(X,scale_technique)\n",
    "        \n",
    "    ''' # model fitting and evaluation: \n",
    "    model.fit(X,y)\n",
    "    \n",
    "    naive_score = model.score(X,y)\n",
    "    cv_score = r2_score(y,cross_val_predict(model,X,y))\n",
    "    \n",
    "    model.fit(X[train],y[train])\n",
    "    true_score = model.score(X[test],y[test])\n",
    "    \n",
    "    gs = \n",
    "    \n",
    "    model_report = ModelingReport(model,X,y,naive_score,cv_score,true_score)\n",
    "    \n",
    "    model_report.remember_config({'alpha':model_alpha,'scaling':scale_technique,\n",
    "                                  'get_dummies':get_dummies,'features':X.shape[1]})\n",
    "    \n",
    "    return model_report'''\n",
    "\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getXy(\n",
    "    df,\n",
    "    target = 'SalePrice',\n",
    "    ignore_colums = None,\n",
    "    consider_columns = None,\n",
    "    \n",
    "    drop_col_if_contains_nan = True,\n",
    "    \n",
    "    cast_into_other = [],\n",
    "    \n",
    "    get_dummies = True, \n",
    "    dummy_columns = None,\n",
    "    do_drop_first = False,\n",
    "    \n",
    "    scale_technique = None):\n",
    "    \n",
    "    '''This function performs most actions that would normaly be associated to preparing \n",
    "    a frature and target matrix for procesing'''\n",
    "    \n",
    "    try:\n",
    "        test = (df['YrSold'] == 2010).values\n",
    "        train = (df['YrSold'] != 2010).values\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    X = df.drop([target],axis=1)\n",
    "    y = df[target]\n",
    "    \n",
    "    # using specific colums or ignoring others\n",
    "    if consider_columns != None:\n",
    "        X = X[consider_columns]\n",
    "    if ignore_colums != None:\n",
    "        X = X.drop([col for col in ignore_colums if col in X.columns],axis = 1)\n",
    "\n",
    "    # drop columns or rows when a a missing value is found.\n",
    "    if drop_col_if_contains_nan:\n",
    "        X = X.dropna(how = 'any',axis = 1)\n",
    "    else:\n",
    "        X = X.dropna(how = 'any',axis = 0)\n",
    "        \n",
    "    # Perform a map from old values to new values on specific columns.\n",
    "    for col,di in cast_into_other:\n",
    "        X[col] = X[col].apply(lambda x: immutable_replace(x,di))\n",
    "\n",
    "    # Get dummie variables: This will dummify columns if you specify them, \n",
    "    # or dummify all non numeric columns if you do not specify any.\n",
    "    \n",
    "    if get_dummies == True or dummy_columns != None:\n",
    "        if dummy_columns == None: dummy_columns = [col for col in X.columns if col not in X.describe().columns]\n",
    "        X = pd.get_dummies(data = X,columns = dummy_columns, drop_first=do_drop_first)\n",
    "        X.columns = [col.replace(' ','_') for col in X.columns]\n",
    "    else:\n",
    "        if dummy_columns == None: dummy_columns = [col for col in X.columns if col not in X.describe().columns]\n",
    "        X = X.drop(dummy_columns,axis=1)\n",
    "\n",
    "    # Perform scaling\n",
    "    if scale_technique != None:\n",
    "        X = dataframe_scaler(X,scale_technique)\n",
    "\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"data-science-workflow.jpg\" style=\" margin: 15px; height: 120px\"></center>\n",
    "\n",
    "### 1. Parsing the data\n",
    "#### 1.1 Introducing the data\n",
    "\n",
    "In this project we will be working with the Ames housing data set that consists of records detailing 1460 sales of various properties from 2006 to 2010 in the city of Ames, Iowa. Of these, 1450 records pertain to the sale of residential properties.\n",
    "\n",
    "<a href=\"https://git.generalassemb.ly/raw/DSI-LDN-3/lessons-repo/master/projects/project-02/data_description.txt?token=AAAY4q6W44WqbDLYg_WJiPApoQi-l2qrks5ZeROlwA%3D%3D\" target=\"_blank\">Feature Descriptions</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('./housing.csv')\n",
    "data_set.drop(['Id'],axis=1,inplace=True)\n",
    "\n",
    "residential = data_set['MSZoning'].isin(['FV','RH','RL','RM'])\n",
    "\n",
    "df = DataFrameHelper(data_set[residential])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 80 features associated with a sale are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.pcolumns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soon we will clasify these properties as either:\n",
    "\n",
    "    1. Fixed         (it would not be fesable to alter this attributes)\n",
    "    2. Alterable     (it would be possible to alter this attributes)\n",
    "    3. Incidental    (it is a property of the specific sale)\n",
    "    4. Derivative    (it can be deduced to a high degree of accuracy from other properties)\n",
    "    \n",
    "But first we inspect our data for missing values and deal with them in a case-by-case basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Verifying the quality of the data\n",
    "\n",
    "##### 1.2.1 Dealing with missing values\n",
    "\n",
    "We seek to identify and replace our missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first concern is to handle the attributes with missing values. \n",
    "\n",
    "These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examine_closer = [col for col in df.columns if df[col].isnull().any()]\n",
    "plist(examine_closer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we concentrate on attributes with missing values where some of the present etries are strings.\n",
    "\n",
    "We look at their unique values and the frequency of their incidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examine_closer_str = [col for col in examine_closer if df[col].apply(lambda x: isinstance(x,str)).any()]\n",
    "examine_closer_num = [col for col in examine_closer if col not in examine_closer_str]\n",
    "df.plot_value_occurences(columns = examine_closer_str,xmarks = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice many of these missing values corespond to the 'NA' value in the .csv file used to indicate that a feature is not pressent. We replace these with the string 'DescribesMissing'. We do this for 2 reasons:\n",
    "\n",
    "    1. For many of these features we will end up using dummy variables, which do not \n",
    "       handle np.nan well, but can easily incoporate one more category. \n",
    "    \n",
    "    2. By enforcing concistency we hope we can later inspect these values further \n",
    "       perhaps as part of some feature egeneering.\n",
    "    \n",
    "The features for which we replace nan with 'DescriptorMissing' are: \n",
    "\n",
    "    BsmtQual      BsmtCond      BsmtExposure  BsmtFinType1  BsmtFinType2      FireplaceQu   \n",
    "    GarageType    GarageFinish  GarageQual    GarageCond    PoolQC        \n",
    "\n",
    "However, for:\n",
    "\n",
    "    Alley         Fence         MiscFeature\n",
    "\n",
    "we replace missing values with the string 'None' following the convention used in the describing the type of facade (MasVnrType). In describing the type of covering of the walls, they allow the abscense of any covering to be a valid covering kind in and of itself.\n",
    "\n",
    "\n",
    "\n",
    "Regarding MasVnrType itself:\n",
    "\n",
    "we could replace nan with 'None', but this would amount to assuming data input errors. Rather than mofing forward with this assumption, we explore another possibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['MasVnrType'].isnull()][['MasVnrType','SaleCondition','YearRemodAdd','YrSold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, 3 of the 8 properties with nan MasVnrType were only partialy built. It would be wrong to assume any one kind of verneer will be used (or intentionaly left with no veneer). Our plan is then to replace nan with \"CouldNotBeInferred\" in the understanding that at the time of creating dummie variables, records with \"CouldNotBeInferred\" will given values between 0 and 1 in the pertinent dummie variables such that they add up to 1 and correspond to the corresponding ratio of houses with each property. By doing this the model can benefit from the information in other features of the record without us imposing assumptions. \n",
    "\n",
    "We could apply the same reasoning to Electrical, where we the missing value corresponds a property we belive is undergoing remodelations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['Electrical'].isnull()][['Electrical','CentralAir','SaleCondition','YearBuilt','YearRemodAdd','YrSold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we choose to side with a 'nearest-neighbors-style' heuristic, and impute a value of \"SBrkr\" to this nan value.\n",
    "\n",
    "As a justification note that property 1379 was built in 2006, and 100% of properties built between 1965 and 2010 have used \"SBrkr\" as their Electrical system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[np.abs(df['YearBuilt'] - 2007) < 42]['Electrical'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descriptors = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu',\n",
    "               'GarageType','GarageFinish','GarageQual','GarageCond','PoolQC']\n",
    "\n",
    "df.fillna({col:'DescribesMissing' for col in descriptors},inplace = True)\n",
    "\n",
    "df.fillna({'Alley':'None','Fence':'None','MiscFeature':'None'},inplace = True)\n",
    "\n",
    "df.fillna({'MasVnrType':'CouldNotBeInferred'},inplace = True)\n",
    "\n",
    "df.fillna({'Electrical':'SBrkr'},inplace = True)\n",
    "\n",
    "_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It remains for us to deal with the missing entries in columns that are mostly numeric, these are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plist([c for c in examine_closer if c not in examine_closer_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interpret a missing value in LotFrontage and MasVnrArea to represent a length and area of 0 respectively. However, no such easy way of dealing with GarageYrBlt is available. One option would be to drop the 37 records for which there is a missing value in GarageYrBlt, but we don't wish to omit the properties without a garage from our model since we belive the precence or absence of a garage may be very significant. \n",
    "\n",
    "Moreover we have pleanty of information regarding the garage of the properties that have them. And a garage area of 0 is a surefire way to deduce the absence of a garage, and hece of a GarageYrBlt value.\n",
    "\n",
    "We will soon consider dropping the feature from our analysis, but for the time being, we replace nan with \"DescribesMissing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna({'LotFrontage':0,'MasVnrArea':0},inplace=True)\n",
    "\n",
    "df.fillna({'GarageYrBlt':'DescribesMissing'},inplace = True)\n",
    "\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].apply(lambda x: str(x))\n",
    "\n",
    "_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we note that the MSSubClass attribute is encoded as integers. However, it is clearly meant to be a category. We replace the integer codes with their coresponding category expressed as a string. This gives us the a DataFrame with no missing values moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSSubClass_dict ={\n",
    "            20:'1-STORY 1946 & NEWER ALL STYLES',\n",
    "            30:'1-STORY 1945 & OLDER',\n",
    "            40:'1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "            45:'1-1/2 STORY - UNFINISHED ALL AGES',\n",
    "            50:'1-1/2 STORY FINISHED ALL AGES',\n",
    "            60:'2-STORY 1946 & NEWER',\n",
    "            70:'2-STORY 1945 & OLDER',\n",
    "            75:'2-1/2 STORY ALL AGES',\n",
    "            80:'SPLIT OR MULTI-LEVEL',\n",
    "            85:'SPLIT FOYER',\n",
    "            90:'DUPLEX - ALL STYLES AND AGES',\n",
    "            120:'1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n",
    "            150:'1-1/2 STORY PUD - ALL AGES',\n",
    "            160:'2-STORY PUD - 1946 & NEWER',\n",
    "            180:'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n",
    "            190:'2 FAMILY CONVERSION - ALL STYLES AND AGES'}\n",
    "\n",
    "df['MSSubClass'] = df['MSSubClass'].apply(lambda x: immutable_replace(x,MSSubClass_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Feature selection.\n",
    "\n",
    "Let us take a quick look at our current feature matrix, and the individual power of attributes in predicting our sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = getXy(df)\n",
    "\n",
    "df_fp = DataFrameHelper(pd.concat([X,y],axis = 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kkl = df_fp.corr().applymap(lambda x:1 if x > 0.5 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = [col for col in kkl.columns if kkl[col].sum() == 3]\n",
    "kkn = kkl[tf].loc[tf,:]\n",
    "sns.heatmap(kkn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.polyfit(df['MoSold'],df['SalePrice'],1,full=True)\n",
    "np.polyfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Idenfiying superfluous features.\n",
    "\n",
    "Before we begin developing a model for sale price, we take a moment to explore the 'redundancy' in our data. As we shall see, several attributes of a sale are merely linear combinations of other attributes. We can identify these situations for numeric features by by setting $x_i$ as the target of a plain linerar regression using features \n",
    "\n",
    "$$x_1,...x_{i-1},-\\square-,x_{i+1},...,x_{n}$$\n",
    "\n",
    "to predict the values of $x_i$. We should then look out for an $R^2$ value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerics = df.describe().columns.tolist()\n",
    "\n",
    "def naive_lm_predict(attributes,\n",
    "                     ignore =None,\n",
    "                    verbose = 0):\n",
    "    coef_storage = {}\n",
    "    results = []\n",
    "    if verbose > 1: print('Predicting:\\n{}'.format('_'*_chars_per_line))\n",
    "    \n",
    "    for col in attributes:\n",
    "        if verbose > 1: print(col, end='; ')\n",
    "        X,y = getXy(df,target=col,ignore_colums=ignore)\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X,y)\n",
    "        score = lm.score(X,y) \n",
    "        coef_storage[col] = pd.DataFrame({'atr':X.columns, 'coef':lm.coef_})\n",
    "        results.append(col.ljust(14)+':'+str(round(score,4)))\n",
    "\n",
    "    if verbose > 1: print('\\n\\nResults:\\n{}'.format('_'*_chars_per_line))\n",
    "    if verbose > 0: plist(results,col_num=4,spacing=24)\n",
    "    return (results, coef_storage)\n",
    "\n",
    "#_ = naive_lm_predict(numerics[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflecting on the results above guides much of what follows. So let us Transcribe them for ease of reference:\n",
    "\n",
    "    LotFrontage   :0.4574   LotArea       :0.7219   OverallQual   :0.8318   OverallCond   :0.6436   \n",
    "    YearBuilt     :0.9443   YearRemodAdd  :0.7318   MasVnrArea    :0.6882   BsmtFinSF1    :1.0      \n",
    "    BsmtFinSF2    :1.0      BsmtUnfSF     :1.0      TotalBsmtSF   :1.0      1stFlrSF      :1.0      \n",
    "    2ndFlrSF      :1.0      LowQualFinSF  :1.0      GrLivArea     :1.0      BsmtFullBath  :0.6737   \n",
    "    BsmtHalfBath  :0.333    FullBath      :0.7651   HalfBath      :0.6898   BedroomAbvGr  :0.7376   \n",
    "    KitchenAbvGr  :0.8127   TotRmsAbvGrd  :0.859    Fireplaces    :0.8728   GarageCars    :0.8807   \n",
    "    GarageArea    :0.8714   WoodDeckSF    :0.3592   OpenPorchSF   :0.4338   EnclosedPorch :0.4121   \n",
    "    3SsnPorch     :0.188    ScreenPorch   :0.2904   PoolArea      :0.9959   MiscVal       :0.966    \n",
    "    MoSold        :0.2123   YrSold        :0.2577   SalePrice     :0.9335   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "And incidentaly we do indeed confirm that, for each of the 1450 properties:\n",
    "\n",
    "$$\\text{TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF}$$\n",
    "\n",
    "$$\\text{GrLivArea = 1stFlrSF + 2ndFlrSF + LowQualFinSF}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_logreg_predict(attributes, myC = 10**10, ignore= None):\n",
    "    coef_storage = {}\n",
    "    results = []\n",
    "    print('Predicting:\\n{}'.format('_'*_chars_per_line))\n",
    "    for col in attributes:\n",
    "        print(col, end='; ')\n",
    "        X,y = getXy(df,target=col, ignore_colums= ignore)\n",
    "        logreg = LogisticRegression(C = myC)\n",
    "        logreg.fit(X,y)\n",
    "        score = logreg.score(X,y) \n",
    "        results.append(col.ljust(14)+':'+str(round(score,4)))\n",
    "    print('\\n\\nResults:\\n{}'.format('_'*_chars_per_line))\n",
    "    plist(results,col_num=4,spacing=24)\n",
    "    return (results, coef_storage)\n",
    "\n",
    "categoric = [col for col in df.columns if col not in numerics]\n",
    "\n",
    "#_ = naive_logreg_predict(categoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding output is:\n",
    "\n",
    "    Predicting:\n",
    "    __________________________________________________________________________________________________________\n",
    "    MSSubClass; MSZoning; Street; Alley; LotShape; LandContour; Utilities; LotConfig; LandSlope; Neighborhood;\n",
    "    Condition1; Condition2; BldgType; HouseStyle; RoofStyle; RoofMatl; Exterior1st; Exterior2nd; MasVnrType;\n",
    "    ExterQual; ExterCond; Foundation; BsmtQual; BsmtCond; BsmtExposure; BsmtFinType1; BsmtFinType2; Heating;\n",
    "    HeatingQC; CentralAir; Electrical; KitchenQual; Functional; FireplaceQu; GarageType; GarageYrBlt; GarageFinish;\n",
    "    GarageQual; GarageCond; PavedDrive; PoolQC; Fence; MiscFeature; SaleType; SaleCondition; \n",
    "\n",
    "    Results:\n",
    "    _____________________________________________________________________________________________\n",
    "    MSSubClass    :0.8159   MSZoning      :0.8759   Street        :1.0      Alley         :0.9393   \n",
    "    LotShape      :0.7131   LandContour   :0.9062   Utilities     :1.0      LotConfig     :0.7234   \n",
    "    LandSlope     :0.9531   Neighborhood  :0.4966   Condition1    :0.8621   Condition2    :0.9938   \n",
    "    BldgType      :0.9034   HouseStyle    :0.8628   RoofStyle     :0.8076   RoofMatl      :0.9848   \n",
    "    Exterior1st   :0.5124   Exterior2nd   :0.4834   MasVnrType    :0.8793   ExterQual     :0.8807   \n",
    "    ExterCond     :0.8821   Foundation    :0.8028   BsmtQual      :0.8269   BsmtCond      :0.9241   \n",
    "    BsmtExposure  :0.7021   BsmtFinType1  :0.6731   BsmtFinType2  :0.9379   Heating       :0.9834   \n",
    "    HeatingQC     :0.6248   CentralAir    :0.9538   Electrical    :0.9152   KitchenQual   :0.7855   \n",
    "    Functional    :0.9317   FireplaceQu   :0.6207   GarageType    :0.7972   GarageYrBlt   :0.3021   \n",
    "    GarageFinish  :0.6634   GarageQual    :0.9559   GarageCond    :0.9641   PavedDrive    :0.9276   \n",
    "    PoolQC        :1.0      Fence         :0.8097   MiscFeature   :0.9972   SaleType      :0.891    \n",
    "    SaleCondition :0.8421   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ress = {}\n",
    "for col in X.columns:\n",
    "     ress[col] = naive_lm_predict(['SalePrice'], ignore = [col])[1]\n",
    "\n",
    "ress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = implement_modeling(df, target='TotalBsmtSF',ignore_colums=decide_to_ignore)\n",
    "\n",
    "lm.fit(X,y)\n",
    "\n",
    "pd.DataFrame({'atr':X.columns,'coef':lm.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical = [col for col in df.columns if col not in df.describe().columns and col not in incidental]\n",
    "df.plot_value_occurences(columns=categorical, mn = (7,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "paramgrid = {'alpha':np.logspace(-4,4,3)}\n",
    "\n",
    "ridge = Ridge()\n",
    "gs = GridSearchCV(ridge, \n",
    "                  param_grid=paramgrid,\n",
    "                  cv = 2, \n",
    "                  n_jobs=3, \n",
    "                  verbose=4)\n",
    "\n",
    "A,B = implement_modeling(df, ignore_colums=decide_to_ignore)\n",
    "\n",
    "gs.fit(A,B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge.fit(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further inspection reveals that all but one of the properties has access to all public "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfixed = ['MSSubClass','MSZoning','LotFrontage','LotArea','Street','Alley','LotShape','LandContour','Utilities',\n",
    "          'LandSlope','LotConfig','Neighborhood','Condition1','Condition2','YearBuilt','YearRemodAdd','RoofStyle',\n",
    "          'MasVnrType','MasVnrArea','Foundation','BsmtQual','BsmtExposure','BsmtFinSF1','BsmtFinSF2','Heating',\n",
    "          '2ndFlrSF','KitchenAbvGr','Fireplaces','GarageType','GarageCars','GarageArea']\n",
    "\n",
    "kalterable = ['RoofMatl','Exterior1st','Exterior2nd','ExterQual','ExterCond','BsmtCond','BsmtFinType1',\n",
    "              'BsmtFinType2','BsmtUnfSF','HeatingQC','CentralAir','Electrical','1stFlrSF','GrLivArea',\n",
    "              'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','Bedroom','KitchenQual','TotRmsAbvGrd',\n",
    "              'Functional','FireplaceQu','GarageFinish','GarageQual','GarageCond','PavedDrive','WoodDeckSF',\n",
    "              'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','PoolQC','Fence',\n",
    "              'MiscFeature','MiscVal']\n",
    "\n",
    "    \n",
    "kderivative = ['BldgType','HouseStyle','OverallQual','OverallCond','LowQualFinSF','TotalBsmtSF']\n",
    "\n",
    "kincidental = ['MoSold','YrSold','SaleType','SaleCondition','SalePrice']\n",
    "\n",
    "len(kalterable + kfixed +kderivative +kincidental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "kincidental == incidental\n",
    "\n",
    "[f for f in kfixed if f not in fixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape',\n",
    "         'LandContour',  'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "         'Condition2', 'BldgType', 'HouseStyle', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
    "         'Foundation', 'BsmtExposure', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "         'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
    "         'TotRmsAbvGrd', 'Fireplaces', 'GarageType', 'GarageCars', 'GarageArea']\n",
    "\n",
    "incidental = ['MoSold','YrSold','SaleType','SaleCondition','SalePrice']\n",
    "\n",
    "alterable = [col for col in df.columns if col not in fixed and col not in incidental]\n",
    "\n",
    "print('\\nFixed:\\n{}'.format('_'*_chars_per_line))\n",
    "plist(fixed)\n",
    "print('\\nAlterable:\\n{}'.format('_'*_chars_per_line))\n",
    "plist(alterable)\n",
    "print('\\nIncidental:\\n{}'.format('_'*_chars_per_line))\n",
    "plist(incidental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do not consider it possible to alter the value of an attribute when it relates to an aspect of the house that is not present. As such, we frown on the idea of improving the PoolQC in a house where PoolArea is 0 and the like.\n",
    "\n",
    "At this time we have not implemented a check in our code that prevents a user from speculating, and the linear model we implement will not distinguish between valid and nonsensical speculation. User caution is adviced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This very much pushes us to examine attributes with missing values before moving forwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When possible we NaN with 0, such as when describing the length of pavement \n",
    "\n",
    "We establish a convention: \n",
    "\n",
    "    1. We use 'NotPresent' to indicate the physical absence of a feature.\n",
    "        eg. The Alley attribute that states the type of alley leading up to the house will have:\n",
    "           Grvl          When it is a gravel road\n",
    "           Pave          When it is a paved road\n",
    "           NotPresent    When there is no alley leading up to the house\n",
    "        \n",
    "    2. We use 'NotApplicable' to indicate a metaphysical absence, such as the quality of a missing feature.\n",
    "        eg. The quality of a pool when the house has no pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot_value_occurences(columns=df.columns.tolist()[0:17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data_cleaning.set_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in [col for col in df.columns if types_df[col][\"<class 'str'>\"] > 0]:\n",
    "    print(col+':')\n",
    "    plist(df[col].unique(), spacing=10,rstart = '> ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class DataExplorer(DataFrameHelper):\n",
    "\n",
    "    def explore_correlation(self,):\n",
    "        sns.regplot(self[cols],y,order=2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = DataExplorer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = (df['YrSold'] == 2010).values\n",
    "train = (df['YrSold'] != 2010).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat = pd.DataFrame()\n",
    "for st in [None,'S','M']:\n",
    "    for it in [True,False]:\n",
    "        dat = pd.concat([dat,implement_modeling(df,model='lasso',\n",
    "                                               consider_columns = fixed,\n",
    "                                               get_dummies=True,\n",
    "                                               scale_technique=st,\n",
    "                                               internal_norm = it).to_df()])\n",
    "\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implement_modeling(df,model='ridge',scale_technique='M',\n",
    "                   consider_columns = fixed,\n",
    "                   get_dummies=True).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implement_modeling(df,model='ridge',scale_technique=None,\n",
    "                   consider_columns = fixed,\n",
    "                   get_dummies=True).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implement_modeling(df,model='ridge',scale_technique=None,\n",
    "                   consider_columns = fixed,\n",
    "                   get_dummies=True,\n",
    "                   internal_norm = True).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_space = {model:['lm','ridge','lasso'],\n",
    "                    {alpha : [0.1,1,10,100],\n",
    "        for consider_col in [fixed]:\n",
    "            for scale_technique in [None,'S','M']:\n",
    "                for ddf in [True,False]:\n",
    "\n",
    "def hyper_parameter_explorer(di)\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat = pd.DataFrame()\n",
    "for mod in ['ridge']:\n",
    "    for alpha in [0.1,1,10,100]:\n",
    "        for consider_col in [fixed]:\n",
    "            for scale_technique in [None,'S','M']:\n",
    "                for ddf in [True,False]:\n",
    "                    \n",
    "                    key = (mod.rjust(7)\n",
    "                       +' alpha='+str(round(alpha,3)).rjust(4)\n",
    "                       +' Scaled by '+str(scale_technique).rjust(5)\n",
    "                       +' Dropping frist: '+str(ddf).rjust(5))\n",
    "                    print (key)\n",
    "                    \n",
    "                    report = implement_modeling(df1,model=mod,consider_columns=consider_col,\n",
    "                                                scale_technique = scale_technique,model_alpha=alpha,\n",
    "                                                do_drop_first = ddf)\n",
    "                    \n",
    "                    dat = pd.concat([dat, report.to_df()],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.reset_index().sort_values('cv_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort = sorted([(di[key].true_score.round(4),key) for key in di.keys()])\n",
    "for (x,y) in sort: print(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    k=np.sqrt(i)\n",
    "    print (i,np.floor(k+1) * np.floor(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(0.85340352664490027, 'ridge10None')\n",
    "\n",
    "0.85426008217280969 ridge10None after!!!\n",
    "\n",
    "(0.87057883511318945, 'ridge10None')]\n",
    "\n",
    "\n",
    "    (0.87057883511318945, 'ridge10NoneTrue'),\n",
    "    (0.87113126001225183, 'ridge10NoneFalse')]\n",
    "\n",
    "\n",
    "    (0.87057883511318945, 'ridge10NoneTrue'),\n",
    "     (0.87113126001225183, 'ridge10NoneFalse') worked better than alpha = 100\n",
    "\n",
    "\n",
    "before altering the qual to num:\n",
    "\n",
    "        (0.8671087710751757, 'ridge alpha=100 Scaled by S Dropping frist: False'),\n",
    "     (0.87057883511318945, 'ridge alpha=10 Scaled by None Dropping frist: True'),\n",
    "     (0.87113126001225183, 'ridge alpha=10 Scaled by None Dropping frist: False')]\n",
    "     \n",
    "after \n",
    "\n",
    "     (0.8671087710751757, 'ridge alpha=100 Scaled by S Dropping frist: False'),\n",
    "     (0.87057883511318945, 'ridge alpha=10 Scaled by None Dropping frist: True'),\n",
    "     (0.87113126001225183, 'ridge alpha=10 Scaled by None Dropping frist: False')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datatat = pd.read_csv('../project-02/housing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(datatat.dtypes.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(datatat.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(datatat.applymap(type)).unique().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "{k:{key:datatat[key].apply(type).value_counts(dropnan=False) for key in datatat.columns} for }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({key:datatat[key].apply(extended_type).value_counts(dropna = False) for key in datatat.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://stackoverflow.com/questions/27934885/how-to-hide-code-from-cells-in-ipython-notebook-visualized-with-nbviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.explore_types().ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['BsmtFinSF1'] > df['1stFlrSF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[535,'BsmtQual':'GrLivArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[535,'BsmtQual':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['MSSubClass'] == 190].apply(lambda x: x['BsmtFinSF1'] > )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(df.explore_types().iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def objects_by_id(id_):\n",
    "    for obj in gc.get_objects():\n",
    "        if id(obj) == id_:\n",
    "            return obj\n",
    "    raise Exception(\"No found\")\n",
    "    \n",
    "X = objects_by_id(0x10a5a07b8)\n",
    "\n",
    "test = (df['YrSold'] == 2010).values\n",
    "train = (df['YrSold'] != 2010).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incidental<sup>[1](#myfootnote1)</sup>.\n",
    "<a name=\"myfootnote1\">1</a>: This is a footnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.MiscVal.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df.MiscFeature.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nan*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for col in examine_closer:\n",
    "    if col not in examine_closer_str:\n",
    "        print(col+':\\n{}'.format('_'*115))\n",
    "        plist(df[col].unique(), spacing=7,col_num=16)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    BsmtFinSF1\n",
    "    BsmtFinSF2\n",
    "    BsmtUnfSF\n",
    "    TotalBsmtSF\n",
    "    1stFlrSF\n",
    "    2ndFlrSF\n",
    "    LowQualFinSF\n",
    "    GrLivArea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
